{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T21:50:31.030451Z",
     "start_time": "2025-04-11T21:49:33.428746Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ----------------------\n",
    "# 1. Data Preparation\n",
    "# ----------------------\n",
    "# Load and merge data\n",
    "looks_df = pd.read_csv('looks.csv')  # Columns: look_id, category, product_id\n",
    "products_df = pd.read_csv('products.csv')  # Columns: product_id, product_name\n",
    "merged_df = pd.merge(looks_df, products_df, on='product_id', how='left')\n",
    "\n",
    "# Group products by look\n",
    "look_products = merged_df.groupby('look_id').agg({\n",
    "    'product_name': list,\n",
    "    'category': 'first',  # Take the first category (assumes same per look)\n",
    "    'product_id': list\n",
    "}).reset_index()\n",
    "\n",
    "# ----------------------\n",
    "# 2. Generate Embeddings\n",
    "# ----------------------\n",
    "# Initialize sentence transformer model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate product embeddings\n",
    "products_df['product_embedding'] = products_df['product_name'].apply(\n",
    "    lambda x: embedding_model.encode(x, convert_to_numpy=True)\n",
    ")\n",
    "\n",
    "# Create look embeddings by averaging product embeddings\n",
    "def get_look_embedding(product_ids):\n",
    "    product_embs = products_df[products_df['product_id'].isin(product_ids)]['product_embedding'].tolist()\n",
    "    if not product_embs:  # Handle empty case\n",
    "        return np.zeros(384)  # Default size for all-MiniLM-L6-v2\n",
    "    return np.mean(np.stack(product_embs), axis=0)\n",
    "\n",
    "look_products['look_embedding'] = look_products['product_id'].apply(get_look_embedding)\n",
    "\n",
    "# ----------------------\n",
    "# 3. PyTorch Model\n",
    "# ----------------------\n",
    "class RecommendationModel(nn.Module):\n",
    "    def __init__(self, input_dim=384, hidden_dim=256, output_dim=128):\n",
    "        super(RecommendationModel, self).__init__()\n",
    "        self.query_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        self.look_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, query, look):\n",
    "        query_emb = self.query_encoder(query)\n",
    "        look_emb = self.look_encoder(look)\n",
    "        return torch.cosine_similarity(query_emb, look_emb, dim=1)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RecommendationModel().to(device)\n",
    "\n",
    "# Note: Training is skipped here as SentenceTransformer embeddings are robust.\n",
    "# If fine-tuning is desired, use paired query-look data and train as below:\n",
    "\"\"\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "look_embeddings = torch.FloatTensor(np.stack(look_products['look_embedding'])).to(device)\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(look_embeddings, look_embeddings)\n",
    "    loss = criterion(outputs, torch.ones_like(outputs))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------\n",
    "# 5. Recommendation System\n",
    "# ----------------------\n",
    "def get_recommendations(user_query, top_k=5):\n",
    "    # Encode user query\n",
    "    query_embedding = embedding_model.encode(user_query, convert_to_numpy=True)\n",
    "    query_tensor = torch.FloatTensor(query_embedding).unsqueeze(0).to(device)\n",
    "\n",
    "    # Prepare look embeddings\n",
    "    look_embeddings = torch.FloatTensor(np.stack(look_products['look_embedding'])).to(device)\n",
    "\n",
    "    # Get similarities\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        similarities = model(query_tensor.repeat(len(look_embeddings), 1), look_embeddings)\n",
    "\n",
    "    # Get top-k looks\n",
    "    _, indices = torch.topk(similarities, k=min(top_k, len(look_products)), dim=0)\n",
    "    recommended_looks = look_products.iloc[indices.cpu().numpy()]\n",
    "\n",
    "    # Aggregate unique product names\n",
    "    all_product_names = []\n",
    "    for _, row in recommended_looks.iterrows():\n",
    "        all_product_names.extend(row['product_name'])\n",
    "    # Return unique product names\n",
    "    return list(dict.fromkeys(all_product_names))[:10]  # Limit to 10 unique products\n",
    "\n",
    "# ----------------------\n",
    "# 6. Example Usage\n",
    "# ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example query\n",
    "    user_query = \"casual summer outfit\"\n",
    "\n",
    "    # Get recommendations\n",
    "    recommendations = get_recommendations(user_query)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nRecommendations for '{user_query}':\")\n",
    "    for idx, product in enumerate(recommendations, 1):\n",
    "        print(f\"{idx}. {product}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b9fac80fc274887922e93dac77f8318"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\VENV\\cuda313\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kami\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2afcee4129d24e3eb6b12724f75bc41a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7e629d2a74c47698d627f7bc1608f71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0894d96643d649978af15d9726569ee8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4c76677f0194bd3824bb8b91412f41a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6932a86e7d48461a868d7c32beb11b93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "595a42511dab43719c5300ee9a19c683"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27d237f3fabd443ea21ce676faea6352"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9132885292814873bc1c463aa2d5381f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35b769b69f754e01bbd695dd959fc275"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "037a590b1a39416ea3f9bd987d0264e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for 'casual summer outfit':\n",
      "1. red printed polo shirt\n",
      "2. gray silk plain skirt\n",
      "3. brown printed flats\n",
      "4. gray cotton polo shirt\n",
      "5. white silk skirt\n",
      "6. white printed flats\n",
      "7. green leather polo shirt\n",
      "8. pink wool striped skirt\n",
      "9. pink nylon slim-fit polo shirt\n",
      "10. black wool printed skirt\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f9aa2cbb42d5ca98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
